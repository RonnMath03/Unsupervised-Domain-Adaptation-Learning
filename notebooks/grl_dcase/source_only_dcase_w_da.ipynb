{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wCdWj_Ww36Bq"
   },
   "source": [
    "# Implementation of baseline (source only) for UDA on DCASE TAU URBAN 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from hear21passt.base import get_basic_model\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'Simplified_Audio_Classifier'\n",
    "print(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaSSTFeatureExtractor(torch.nn.Module):\n",
    "    def __init__(self, device=None):\n",
    "        super(PaSSTFeatureExtractor, self).__init__()\n",
    "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = get_basic_model(mode=\"embed_only\") \n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def forward(self, audio_waveform, sample_rate=32000):\n",
    "        if audio_waveform.dim() == 1:\n",
    "            audio_waveform = audio_waveform.unsqueeze(0)  \n",
    "\n",
    "        audio_waveform = audio_waveform.to(self.device)\n",
    "        \n",
    "        # Allow gradients to flow through PaSST for fine-tuning\n",
    "        features = self.model(audio_waveform)\n",
    "             \n",
    "        return features\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \"\"\"Simplified Classifier\"\"\"\n",
    "    def __init__(self, input_size=768, num_classes=10):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, h):\n",
    "        return self.layer(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, root_dir, csv_file=None, sample_rate=32000, max_length=5):  # Reduced to 5 seconds\n",
    "        self.root_dir = root_dir\n",
    "        self.sample_rate = sample_rate\n",
    "        self.max_length = max_length\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "        self.label_to_idx = {}\n",
    "        \n",
    "        # Load labels from CSV if provided\n",
    "        if csv_file and os.path.exists(csv_file):\n",
    "            df = pd.read_csv(csv_file, delimiter='\\t')\n",
    "            print(f\"CSV columns: {list(df.columns)}\")\n",
    "            \n",
    "            filename_to_label = {}\n",
    "            \n",
    "            # Find label and filename columns\n",
    "            label_col = None\n",
    "            filename_col = None\n",
    "            \n",
    "            for col in df.columns:\n",
    "                if 'label' in col.lower() or 'scene' in col.lower() or 'class' in col.lower():\n",
    "                    label_col = col\n",
    "                    break\n",
    "            \n",
    "            for col in df.columns:\n",
    "                if 'filename' in col.lower() or 'file' in col.lower() or 'name' in col.lower():\n",
    "                    filename_col = col\n",
    "                    break\n",
    "            \n",
    "            if label_col is None or filename_col is None:\n",
    "                if len(df.columns) >= 2:\n",
    "                    filename_col = df.columns[0]\n",
    "                    label_col = df.columns[1]\n",
    "                    print(f\"Using columns: filename='{filename_col}', label='{label_col}'\")\n",
    "                else:\n",
    "                    raise ValueError(\"CSV file must have at least 2 columns\")\n",
    "            \n",
    "            # Get unique labels and create mapping\n",
    "            unique_labels = sorted(df[label_col].unique())\n",
    "            self.label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "            self.idx_to_label = {idx: label for label, idx in self.label_to_idx.items()}\n",
    "            \n",
    "            # Create filename to label mapping\n",
    "            existing_files = set(os.listdir(root_dir))\n",
    "            for _, row in df.iterrows():\n",
    "                csv_filename = row[filename_col]\n",
    "                if '/' in csv_filename:\n",
    "                    csv_filename = csv_filename.split('/')[-1]\n",
    "                \n",
    "                if csv_filename in existing_files:\n",
    "                    filename_to_label[csv_filename] = row[label_col]\n",
    "            \n",
    "            print(f\"Found {len(filename_to_label)} matching files in {root_dir}\")\n",
    "            \n",
    "            # Load files and labels\n",
    "            matched_files = 0\n",
    "            for fname in sorted(os.listdir(root_dir)):\n",
    "                if fname.endswith('.wav'):\n",
    "                    if fname in filename_to_label:\n",
    "                        self.files.append(os.path.join(root_dir, fname))\n",
    "                        scene_label = filename_to_label[fname]\n",
    "                        label_idx = self.label_to_idx[scene_label]\n",
    "                        self.labels.append(label_idx)\n",
    "                        matched_files += 1\n",
    "            \n",
    "            print(f\"Successfully loaded {matched_files} files with labels\")\n",
    "        else:\n",
    "            for fname in sorted(os.listdir(root_dir)):\n",
    "                if fname.endswith('.wav'):\n",
    "                    self.files.append(os.path.join(root_dir, fname))\n",
    "                    self.labels.append(0)\n",
    "            \n",
    "        print(f\"Dataset {root_dir}: {len(self.files)} audio files\")\n",
    "        if self.label_to_idx:\n",
    "            print(f\"Label mapping: {self.label_to_idx}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_path = self.files[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Load audio with reduced length\n",
    "        waveform, sr = librosa.load(audio_path, sr=self.sample_rate, mono=True)\n",
    "        \n",
    "        if self.max_length:\n",
    "            max_samples = int(self.max_length * self.sample_rate)\n",
    "            if len(waveform) > max_samples:\n",
    "                waveform = waveform[:max_samples]\n",
    "        \n",
    "        waveform = torch.tensor(waveform, dtype=torch.float32)\n",
    "        return waveform, label\n",
    "    \n",
    "    def get_num_classes(self):\n",
    "        return len(self.label_to_idx) if self.label_to_idx else 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32  \n",
    "max_audio_length = 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_csv = '/home/teaching/interng1/datasets/dcase/meta.csv'\n",
    "\n",
    "source_train = AudioDataset(\n",
    "    root_dir='/home/teaching/interng1/datasets/dcase/train/source',\n",
    "    csv_file=meta_csv,\n",
    "    max_length=max_audio_length\n",
    ")\n",
    "target_train = AudioDataset(\n",
    "    root_dir='/home/teaching/interng1/datasets/dcase/train/target',\n",
    "    csv_file=meta_csv,\n",
    "    max_length=max_audio_length\n",
    ")\n",
    "test_dataset = AudioDataset(\n",
    "    root_dir='/home/teaching/interng1/datasets/dcase/test',\n",
    "    csv_file=meta_csv,\n",
    "    max_length=max_audio_length\n",
    ")\n",
    "\n",
    "num_classes = max(\n",
    "    source_train.get_num_classes(), \n",
    "    target_train.get_num_classes(),\n",
    "    test_dataset.get_num_classes()\n",
    ")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Source train samples: {len(source_train)}\")\n",
    "print(f\"Target train samples: {len(target_train)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_loader = DataLoader(source_train, batch_size=batch_size, shuffle=True, \n",
    "                          drop_last=True, num_workers=1, pin_memory=False)\n",
    "eval_loader = DataLoader(source_train, batch_size=batch_size, shuffle=False, \n",
    "                        drop_last=False, num_workers=1, pin_memory=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, \n",
    "                        drop_last=False, num_workers=1, pin_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = PaSSTFeatureExtractor().to(DEVICE)  \n",
    "C = Classifier(num_classes=num_classes).to(DEVICE)\n",
    "\n",
    "print(f\"Feature extractor trainable parameters: {sum(p.numel() for p in F.parameters() if p.requires_grad)}\")\n",
    "print(f\"Classifier parameters: {sum(p.numel() for p in C.parameters())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xe = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "F_opt = torch.optim.Adam(F.parameters(), lr=1e-5)  \n",
    "C_opt = torch.optim.Adam(C.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "max_epoch = 50  \n",
    "step = 0\n",
    "\n",
    "\n",
    "ll_c = [] \n",
    "acc_lst = [] \n",
    "\n",
    "print(f\"Starting training for {max_epoch} epochs...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "CSV columns: ['filename', 'scene_label', 'identifier', 'source_label']\n",
      "Found 10215 matching files in /home/teaching/G3/Datasets/train/source\n",
      "Successfully loaded 10215 files with labels\n",
      "Dataset /home/teaching/G3/Datasets/train/source: 10215 audio files\n",
      "Label mapping: {'airport': 0, 'bus': 1, 'metro': 2, 'metro_station': 3, 'park': 4, 'public_square': 5, 'shopping_mall': 6, 'street_pedestrian': 7, 'street_traffic': 8, 'tram': 9}\n",
      "CSV columns: ['filename', 'scene_label', 'identifier', 'source_label']\n",
      "Found 3747 matching files in /home/teaching/G3/Datasets/train/target\n",
      "Successfully loaded 3747 files with labels\n",
      "Dataset /home/teaching/G3/Datasets/train/target: 3747 audio files\n",
      "Label mapping: {'airport': 0, 'bus': 1, 'metro': 2, 'metro_station': 3, 'park': 4, 'public_square': 5, 'shopping_mall': 6, 'street_pedestrian': 7, 'street_traffic': 8, 'tram': 9}\n",
      "CSV columns: ['filename', 'scene_label', 'identifier', 'source_label']\n",
      "Found 2968 matching files in /home/teaching/G3/Datasets/test\n",
      "Successfully loaded 2968 files with labels\n",
      "Dataset /home/teaching/G3/Datasets/test: 2968 audio files\n",
      "Label mapping: {'airport': 0, 'bus': 1, 'metro': 2, 'metro_station': 3, 'park': 4, 'public_square': 5, 'shopping_mall': 6, 'street_pedestrian': 7, 'street_traffic': 8, 'tram': 9}\n",
      "Number of classes: 10\n",
      "Source train samples: 10215\n",
      "Target train samples: 3747\n",
      "Test samples: 2968\n",
      "Warning: FMAX is None setting to 15000 \n",
      "\n",
      "\n",
      " Loading PASST TRAINED ON AUDISET \n",
      "\n",
      "\n",
      "PaSST(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (blocks): Sequential(\n",
      "    (0): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (2): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (3): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (4): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (5): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (6): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (7): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (8): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (9): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (10): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (11): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (pre_logits): Identity()\n",
      "  (head): Sequential(\n",
      "    (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=768, out_features=527, bias=True)\n",
      "  )\n",
      "  (head_dist): Linear(in_features=768, out_features=527, bias=True)\n",
      ")\n",
      "Feature extractor trainable parameters: 86153759\n",
      "Classifier parameters: 99722\n",
      "Starting training for 50 epochs...\n",
      "============================================================\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teaching/anaconda3/lib/python3.12/site-packages/torch/functional.py:730: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at /pytorch/aten/src/ATen/native/SpectralOps.cpp:875.)\n",
      "  return _VF.stft(  # type: ignore[attr-defined]\n",
      "/home/teaching/anaconda3/lib/python3.12/site-packages/hear21passt/models/preprocess.py:71: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/home/teaching/anaconda3/lib/python3.12/site-packages/hear21passt/models/passt.py:304: UserWarning: Input image size (128*500) doesn't match model (128*998).\n",
      "  warnings.warn(f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x torch.Size([32, 1, 128, 500])\n",
      "self.norm(x) torch.Size([32, 768, 12, 49])\n",
      " patch_embed :  torch.Size([32, 768, 12, 49])\n",
      " self.time_new_pos_embed.shape torch.Size([1, 768, 1, 99])\n",
      " CUT time_new_pos_embed.shape torch.Size([1, 768, 1, 49])\n",
      " self.freq_new_pos_embed.shape torch.Size([1, 768, 12, 1])\n",
      "X flattened torch.Size([32, 588, 768])\n",
      " self.new_pos_embed.shape torch.Size([1, 2, 768])\n",
      " self.cls_tokens.shape torch.Size([32, 1, 768])\n",
      " self.dist_token.shape torch.Size([32, 1, 768])\n",
      " final sequence x torch.Size([32, 590, 768])\n",
      " after 12 atten blocks x torch.Size([32, 590, 768])\n",
      "forward_features torch.Size([32, 768])\n",
      "head torch.Size([32, 527])\n",
      "Epoch: 1/50, Step: 0, C Loss: 2.4104 ---- 12:10:10\n",
      "***** Eval Result (Source): 0.2034, Step: 0\n",
      "***** Test Result (Target): 0.1543, Step: 0\n",
      "Epoch: 1/50, Step: 100, C Loss: 1.2431 ---- 12:14:43\n",
      "Epoch: 1/50, Step: 200, C Loss: 0.7482 ---- 12:16:33\n",
      "Epoch: 1/50, Step: 300, C Loss: 0.3754 ---- 12:18:21\n",
      "Epoch 1 completed in 0:08:33.308129\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 2/50\n",
      "Epoch: 2/50, Step: 400, C Loss: 0.3481 ---- 12:20:11\n",
      "Epoch: 2/50, Step: 500, C Loss: 0.5788 ---- 12:21:59\n",
      "***** Eval Result (Source): 0.8536, Step: 500\n",
      "***** Test Result (Target): 0.5162, Step: 500\n",
      "Epoch: 2/50, Step: 600, C Loss: 0.5293 ---- 12:26:28\n",
      "Epoch 2 completed in 0:08:26.015990\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 3/50\n",
      "Epoch: 3/50, Step: 700, C Loss: 0.3907 ---- 12:28:17\n",
      "Epoch: 3/50, Step: 800, C Loss: 0.2626 ---- 12:30:06\n",
      "Epoch: 3/50, Step: 900, C Loss: 0.3677 ---- 12:31:54\n",
      "Epoch 3 completed in 0:05:45.376751\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 4/50\n",
      "Epoch: 4/50, Step: 1000, C Loss: 0.3767 ---- 12:33:43\n",
      "***** Eval Result (Source): 0.9341, Step: 1000\n",
      "***** Test Result (Target): 0.5256, Step: 1000\n",
      "Epoch: 4/50, Step: 1100, C Loss: 0.6849 ---- 12:38:12\n",
      "Epoch: 4/50, Step: 1200, C Loss: 0.4279 ---- 12:40:00\n",
      "Epoch 4 completed in 0:08:25.771939\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 5/50\n",
      "Epoch: 5/50, Step: 1300, C Loss: 0.1328 ---- 12:41:49\n",
      "Epoch: 5/50, Step: 1400, C Loss: 0.3202 ---- 12:43:38\n",
      "Epoch: 5/50, Step: 1500, C Loss: 0.4095 ---- 12:45:26\n",
      "***** Eval Result (Source): 0.9634, Step: 1500\n",
      "***** Test Result (Target): 0.5323, Step: 1500\n",
      "Epoch 5 completed in 0:08:25.778257\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 6/50\n",
      "Epoch: 6/50, Step: 1600, C Loss: 0.2219 ---- 12:49:56\n",
      "Epoch: 6/50, Step: 1700, C Loss: 0.0846 ---- 12:51:44\n",
      "Epoch: 6/50, Step: 1800, C Loss: 0.2829 ---- 12:53:32\n",
      "Epoch: 6/50, Step: 1900, C Loss: 0.0772 ---- 12:55:20\n",
      "Epoch 6 completed in 0:05:45.449930\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 7/50\n",
      "Epoch: 7/50, Step: 2000, C Loss: 0.2124 ---- 12:57:10\n",
      "***** Eval Result (Source): 0.9761, Step: 2000\n",
      "***** Test Result (Target): 0.4919, Step: 2000\n",
      "Epoch: 7/50, Step: 2100, C Loss: 0.2466 ---- 13:01:39\n",
      "Epoch: 7/50, Step: 2200, C Loss: 0.1840 ---- 13:03:27\n",
      "Epoch 7 completed in 0:08:25.946162\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 8/50\n",
      "Epoch: 8/50, Step: 2300, C Loss: 0.6852 ---- 13:05:16\n",
      "Epoch: 8/50, Step: 2400, C Loss: 0.1140 ---- 13:07:04\n",
      "Epoch: 8/50, Step: 2500, C Loss: 0.1572 ---- 13:08:53\n",
      "***** Eval Result (Source): 0.9886, Step: 2500\n",
      "***** Test Result (Target): 0.5216, Step: 2500\n",
      "Epoch 8 completed in 0:08:25.984521\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 9/50\n",
      "Epoch: 9/50, Step: 2600, C Loss: 0.1186 ---- 13:13:23\n",
      "Epoch: 9/50, Step: 2700, C Loss: 0.0113 ---- 13:15:11\n",
      "Epoch: 9/50, Step: 2800, C Loss: 0.0973 ---- 13:16:59\n",
      "Epoch 9 completed in 0:05:45.294280\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 10/50\n",
      "Epoch: 10/50, Step: 2900, C Loss: 0.0978 ---- 13:18:49\n",
      "Epoch: 10/50, Step: 3000, C Loss: 0.2402 ---- 13:20:37\n",
      "***** Eval Result (Source): 0.9870, Step: 3000\n",
      "***** Test Result (Target): 0.5051, Step: 3000\n",
      "Epoch: 10/50, Step: 3100, C Loss: 0.1793 ---- 13:25:05\n",
      "Epoch 10 completed in 0:08:25.718333\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 11/50\n",
      "Epoch: 11/50, Step: 3200, C Loss: 0.2379 ---- 13:26:55\n",
      "Epoch: 11/50, Step: 3300, C Loss: 0.0602 ---- 13:28:43\n",
      "Epoch: 11/50, Step: 3400, C Loss: 0.0660 ---- 13:30:31\n",
      "Epoch: 11/50, Step: 3500, C Loss: 0.0441 ---- 13:32:19\n",
      "***** Eval Result (Source): 0.9969, Step: 3500\n",
      "***** Test Result (Target): 0.4768, Step: 3500\n",
      "Epoch 11 completed in 0:08:25.739532\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 12/50\n",
      "Epoch: 12/50, Step: 3600, C Loss: 0.1354 ---- 13:36:49\n",
      "Epoch: 12/50, Step: 3700, C Loss: 0.1324 ---- 13:38:37\n",
      "Epoch: 12/50, Step: 3800, C Loss: 0.2053 ---- 13:40:25\n",
      "Epoch 12 completed in 0:05:45.279651\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 13/50\n",
      "Epoch: 13/50, Step: 3900, C Loss: 0.2330 ---- 13:42:15\n",
      "Epoch: 13/50, Step: 4000, C Loss: 0.0621 ---- 13:44:03\n",
      "***** Eval Result (Source): 0.9983, Step: 4000\n",
      "***** Test Result (Target): 0.4997, Step: 4000\n",
      "Epoch: 13/50, Step: 4100, C Loss: 0.1190 ---- 13:48:32\n",
      "Epoch 13 completed in 0:08:25.775056\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 14/50\n",
      "Epoch: 14/50, Step: 4200, C Loss: 0.1204 ---- 13:50:21\n",
      "Epoch: 14/50, Step: 4300, C Loss: 0.0165 ---- 13:52:09\n",
      "Epoch: 14/50, Step: 4400, C Loss: 0.0346 ---- 13:53:57\n",
      "Epoch 14 completed in 0:05:45.321736\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 15/50\n",
      "Epoch: 15/50, Step: 4500, C Loss: 0.2029 ---- 13:55:47\n",
      "***** Eval Result (Source): 0.9988, Step: 4500\n",
      "***** Test Result (Target): 0.5384, Step: 4500\n",
      "Epoch: 15/50, Step: 4600, C Loss: 0.1038 ---- 14:00:16\n",
      "Epoch: 15/50, Step: 4700, C Loss: 0.0433 ---- 14:02:04\n",
      "Epoch 15 completed in 0:08:25.800450\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 16/50\n",
      "Epoch: 16/50, Step: 4800, C Loss: 0.0422 ---- 14:03:53\n",
      "Epoch: 16/50, Step: 4900, C Loss: 0.1527 ---- 14:05:41\n",
      "Epoch: 16/50, Step: 5000, C Loss: 0.0255 ---- 14:07:29\n",
      "***** Eval Result (Source): 0.9993, Step: 5000\n",
      "***** Test Result (Target): 0.5243, Step: 5000\n",
      "Epoch: 16/50, Step: 5100, C Loss: 0.1841 ---- 14:11:58\n",
      "Epoch 16 completed in 0:08:25.749307\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 17/50\n",
      "Epoch: 17/50, Step: 5200, C Loss: 0.0078 ---- 14:13:48\n",
      "Epoch: 17/50, Step: 5300, C Loss: 0.2486 ---- 14:15:36\n",
      "Epoch: 17/50, Step: 5400, C Loss: 0.2871 ---- 14:17:24\n",
      "Epoch 17 completed in 0:05:45.216344\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 18/50\n",
      "Epoch: 18/50, Step: 5500, C Loss: 0.0475 ---- 14:19:13\n",
      "***** Eval Result (Source): 0.9985, Step: 5500\n",
      "***** Test Result (Target): 0.5492, Step: 5500\n",
      "Epoch: 18/50, Step: 5600, C Loss: 0.0047 ---- 14:23:42\n",
      "Epoch: 18/50, Step: 5700, C Loss: 0.0288 ---- 14:25:30\n",
      "Epoch 18 completed in 0:08:25.679250\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 19/50\n",
      "Epoch: 19/50, Step: 5800, C Loss: 0.0579 ---- 14:27:19\n",
      "Epoch: 19/50, Step: 5900, C Loss: 0.0316 ---- 14:29:08\n",
      "Epoch: 19/50, Step: 6000, C Loss: 0.2612 ---- 14:30:56\n",
      "***** Eval Result (Source): 0.9999, Step: 6000\n",
      "***** Test Result (Target): 0.5556, Step: 6000\n",
      "Epoch 19 completed in 0:08:25.745396\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 20/50\n",
      "Epoch: 20/50, Step: 6100, C Loss: 0.1645 ---- 14:35:26\n",
      "Epoch: 20/50, Step: 6200, C Loss: 0.0234 ---- 14:37:14\n",
      "Epoch: 20/50, Step: 6300, C Loss: 0.0295 ---- 14:39:02\n",
      "Epoch 20 completed in 0:05:45.170524\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 21/50\n",
      "Epoch: 21/50, Step: 6400, C Loss: 0.0404 ---- 14:40:51\n",
      "Epoch: 21/50, Step: 6500, C Loss: 0.3127 ---- 14:42:39\n",
      "***** Eval Result (Source): 0.9966, Step: 6500\n",
      "***** Test Result (Target): 0.5148, Step: 6500\n",
      "Epoch: 21/50, Step: 6600, C Loss: 0.0077 ---- 14:47:08\n",
      "Epoch 21 completed in 0:08:25.607554\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 22/50\n",
      "Epoch: 22/50, Step: 6700, C Loss: 0.0596 ---- 14:48:57\n",
      "Epoch: 22/50, Step: 6800, C Loss: 0.0099 ---- 14:50:46\n",
      "Epoch: 22/50, Step: 6900, C Loss: 0.1115 ---- 14:52:34\n",
      "Epoch: 22/50, Step: 7000, C Loss: 0.1375 ---- 14:54:22\n",
      "***** Eval Result (Source): 0.9985, Step: 7000\n",
      "***** Test Result (Target): 0.5438, Step: 7000\n",
      "Epoch 22 completed in 0:08:25.733102\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 23/50\n",
      "Epoch: 23/50, Step: 7100, C Loss: 0.0062 ---- 14:58:52\n",
      "Epoch: 23/50, Step: 7200, C Loss: 0.0040 ---- 15:00:40\n",
      "Epoch: 23/50, Step: 7300, C Loss: 0.0567 ---- 15:02:28\n",
      "Epoch 23 completed in 0:05:45.283484\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 24/50\n",
      "Epoch: 24/50, Step: 7400, C Loss: 0.0518 ---- 15:04:18\n",
      "Epoch: 24/50, Step: 7500, C Loss: 0.0827 ---- 15:06:06\n",
      "***** Eval Result (Source): 0.9996, Step: 7500\n",
      "***** Test Result (Target): 0.5296, Step: 7500\n",
      "Epoch: 24/50, Step: 7600, C Loss: 0.0411 ---- 15:10:34\n",
      "Epoch 24 completed in 0:08:25.726085\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 25/50\n",
      "Epoch: 25/50, Step: 7700, C Loss: 0.0293 ---- 15:12:24\n",
      "Epoch: 25/50, Step: 7800, C Loss: 0.0353 ---- 15:14:12\n",
      "Epoch: 25/50, Step: 7900, C Loss: 0.1038 ---- 15:16:00\n",
      "Epoch 25 completed in 0:05:45.284577\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 26/50\n",
      "Epoch: 26/50, Step: 8000, C Loss: 0.0007 ---- 15:17:49\n",
      "***** Eval Result (Source): 0.9999, Step: 8000\n",
      "***** Test Result (Target): 0.5465, Step: 8000\n",
      "Epoch: 26/50, Step: 8100, C Loss: 0.0098 ---- 15:22:18\n",
      "Epoch: 26/50, Step: 8200, C Loss: 0.4873 ---- 15:24:06\n",
      "Epoch 26 completed in 0:08:25.846945\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 27/50\n",
      "Epoch: 27/50, Step: 8300, C Loss: 0.0053 ---- 15:25:56\n",
      "Epoch: 27/50, Step: 8400, C Loss: 0.1255 ---- 15:27:44\n",
      "Epoch: 27/50, Step: 8500, C Loss: 0.3282 ---- 15:29:32\n",
      "***** Eval Result (Source): 1.0000, Step: 8500\n",
      "***** Test Result (Target): 0.5283, Step: 8500\n",
      "Epoch: 27/50, Step: 8600, C Loss: 0.2775 ---- 15:34:01\n",
      "Epoch 27 completed in 0:08:25.796185\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 28/50\n",
      "Epoch: 28/50, Step: 8700, C Loss: 0.0670 ---- 15:35:50\n",
      "Epoch: 28/50, Step: 8800, C Loss: 0.0573 ---- 15:37:38\n",
      "Epoch: 28/50, Step: 8900, C Loss: 0.0700 ---- 15:39:26\n",
      "Epoch 28 completed in 0:05:45.223263\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 29/50\n",
      "Epoch: 29/50, Step: 9000, C Loss: 0.0252 ---- 15:41:16\n",
      "***** Eval Result (Source): 0.9996, Step: 9000\n",
      "***** Test Result (Target): 0.5253, Step: 9000\n",
      "Epoch: 29/50, Step: 9100, C Loss: 0.1246 ---- 15:45:45\n",
      "Epoch: 29/50, Step: 9200, C Loss: 0.0152 ---- 15:47:33\n",
      "Epoch 29 completed in 0:08:26.098177\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 30/50\n",
      "Epoch: 30/50, Step: 9300, C Loss: 0.0140 ---- 15:49:22\n",
      "Epoch: 30/50, Step: 9400, C Loss: 0.0097 ---- 15:51:10\n",
      "Epoch: 30/50, Step: 9500, C Loss: 0.0175 ---- 15:52:59\n",
      "***** Eval Result (Source): 0.9996, Step: 9500\n",
      "***** Test Result (Target): 0.5286, Step: 9500\n",
      "Epoch 30 completed in 0:08:25.788902\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 31/50\n",
      "Epoch: 31/50, Step: 9600, C Loss: 0.0169 ---- 15:57:28\n",
      "Epoch: 31/50, Step: 9700, C Loss: 0.0095 ---- 15:59:17\n",
      "Epoch: 31/50, Step: 9800, C Loss: 0.0023 ---- 16:01:05\n",
      "Epoch 31 completed in 0:05:45.301191\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 32/50\n",
      "Epoch: 32/50, Step: 9900, C Loss: 0.0505 ---- 16:02:54\n",
      "Epoch: 32/50, Step: 10000, C Loss: 0.0144 ---- 16:04:43\n",
      "***** Eval Result (Source): 0.9984, Step: 10000\n",
      "***** Test Result (Target): 0.5175, Step: 10000\n",
      "Epoch: 32/50, Step: 10100, C Loss: 0.0017 ---- 16:09:11\n",
      "Epoch: 32/50, Step: 10200, C Loss: 0.0563 ---- 16:11:00\n",
      "Epoch 32 completed in 0:08:26.181023\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 33/50\n",
      "Epoch: 33/50, Step: 10300, C Loss: 0.0095 ---- 16:12:49\n",
      "Epoch: 33/50, Step: 10400, C Loss: 0.0052 ---- 16:14:37\n",
      "Epoch: 33/50, Step: 10500, C Loss: 0.0011 ---- 16:16:25\n",
      "***** Eval Result (Source): 0.9996, Step: 10500\n",
      "***** Test Result (Target): 0.4990, Step: 10500\n",
      "Epoch 33 completed in 0:08:25.452341\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 34/50\n",
      "Epoch: 34/50, Step: 10600, C Loss: 0.0039 ---- 16:20:55\n",
      "Epoch: 34/50, Step: 10700, C Loss: 0.0017 ---- 16:22:43\n",
      "Epoch: 34/50, Step: 10800, C Loss: 0.0069 ---- 16:24:33\n",
      "Epoch 34 completed in 0:05:47.172187\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 35/50\n",
      "Epoch: 35/50, Step: 10900, C Loss: 0.1569 ---- 16:26:23\n",
      "Epoch: 35/50, Step: 11000, C Loss: 0.0774 ---- 16:28:12\n",
      "***** Eval Result (Source): 0.9998, Step: 11000\n",
      "***** Test Result (Target): 0.5307, Step: 11000\n",
      "Epoch: 35/50, Step: 11100, C Loss: 0.0002 ---- 16:32:42\n",
      "Epoch 35 completed in 0:08:28.091714\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 36/50\n",
      "Epoch: 36/50, Step: 11200, C Loss: 0.0237 ---- 16:34:31\n",
      "Epoch: 36/50, Step: 11300, C Loss: 0.0355 ---- 16:36:20\n",
      "Epoch: 36/50, Step: 11400, C Loss: 0.2100 ---- 16:38:08\n",
      "Epoch 36 completed in 0:05:45.468066\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 37/50\n",
      "Epoch: 37/50, Step: 11500, C Loss: 0.0292 ---- 16:39:57\n",
      "***** Eval Result (Source): 0.9999, Step: 11500\n",
      "***** Test Result (Target): 0.5098, Step: 11500\n",
      "Epoch: 37/50, Step: 11600, C Loss: 0.0126 ---- 16:44:26\n",
      "Epoch: 37/50, Step: 11700, C Loss: 0.0081 ---- 16:46:14\n",
      "Epoch: 37/50, Step: 11800, C Loss: 0.2550 ---- 16:48:03\n",
      "Epoch 37 completed in 0:08:26.147711\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 38/50\n",
      "Epoch: 38/50, Step: 11900, C Loss: 0.0278 ---- 16:49:52\n",
      "Epoch: 38/50, Step: 12000, C Loss: 0.0245 ---- 16:51:40\n",
      "***** Eval Result (Source): 0.9991, Step: 12000\n",
      "***** Test Result (Target): 0.5148, Step: 12000\n",
      "Epoch: 38/50, Step: 12100, C Loss: 0.1719 ---- 16:56:09\n",
      "Epoch 38 completed in 0:08:26.056659\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 39/50\n",
      "Epoch: 39/50, Step: 12200, C Loss: 0.0016 ---- 16:57:59\n",
      "Epoch: 39/50, Step: 12300, C Loss: 0.0231 ---- 16:59:47\n",
      "Epoch: 39/50, Step: 12400, C Loss: 0.0024 ---- 17:01:35\n",
      "Epoch 39 completed in 0:05:45.355468\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 40/50\n",
      "Epoch: 40/50, Step: 12500, C Loss: 0.0168 ---- 17:03:24\n",
      "***** Eval Result (Source): 0.9996, Step: 12500\n",
      "***** Test Result (Target): 0.5121, Step: 12500\n",
      "Epoch: 40/50, Step: 12600, C Loss: 0.1943 ---- 17:07:53\n",
      "Epoch: 40/50, Step: 12700, C Loss: 0.0004 ---- 17:09:41\n",
      "Epoch 40 completed in 0:08:25.473001\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 41/50\n",
      "Epoch: 41/50, Step: 12800, C Loss: 0.0018 ---- 17:11:30\n",
      "Epoch: 41/50, Step: 12900, C Loss: 0.0122 ---- 17:13:19\n",
      "Epoch: 41/50, Step: 13000, C Loss: 0.1320 ---- 17:15:07\n",
      "***** Eval Result (Source): 1.0000, Step: 13000\n",
      "***** Test Result (Target): 0.5034, Step: 13000\n",
      "Epoch 41 completed in 0:08:25.679599\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 42/50\n",
      "Epoch: 42/50, Step: 13100, C Loss: 0.0007 ---- 17:19:37\n",
      "Epoch: 42/50, Step: 13200, C Loss: 0.0109 ---- 17:21:25\n",
      "Epoch: 42/50, Step: 13300, C Loss: 0.0502 ---- 17:23:13\n",
      "Epoch 42 completed in 0:05:45.294944\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 43/50\n",
      "Epoch: 43/50, Step: 13400, C Loss: 0.0353 ---- 17:25:03\n",
      "Epoch: 43/50, Step: 13500, C Loss: 0.0153 ---- 17:26:51\n",
      "***** Eval Result (Source): 0.9999, Step: 13500\n",
      "***** Test Result (Target): 0.5270, Step: 13500\n",
      "Epoch: 43/50, Step: 13600, C Loss: 0.0294 ---- 17:31:19\n",
      "Epoch: 43/50, Step: 13700, C Loss: 0.0520 ---- 17:33:07\n",
      "Epoch 43 completed in 0:08:25.845019\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 44/50\n",
      "Epoch: 44/50, Step: 13800, C Loss: 0.0016 ---- 17:34:57\n",
      "Epoch: 44/50, Step: 13900, C Loss: 0.0032 ---- 17:36:45\n",
      "Epoch: 44/50, Step: 14000, C Loss: 0.0407 ---- 17:38:33\n",
      "***** Eval Result (Source): 0.9995, Step: 14000\n",
      "***** Test Result (Target): 0.5371, Step: 14000\n",
      "Epoch 44 completed in 0:08:25.726988\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 45/50\n",
      "Epoch: 45/50, Step: 14100, C Loss: 0.0793 ---- 17:43:03\n",
      "Epoch: 45/50, Step: 14200, C Loss: 0.0295 ---- 17:44:51\n",
      "Epoch: 45/50, Step: 14300, C Loss: 0.0135 ---- 17:46:40\n",
      "Epoch 45 completed in 0:05:45.383887\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 46/50\n",
      "Epoch: 46/50, Step: 14400, C Loss: 0.0290 ---- 17:48:29\n",
      "Epoch: 46/50, Step: 14500, C Loss: 0.1158 ---- 17:50:17\n",
      "***** Eval Result (Source): 0.9997, Step: 14500\n",
      "***** Test Result (Target): 0.5074, Step: 14500\n",
      "Epoch: 46/50, Step: 14600, C Loss: 0.0040 ---- 17:54:47\n",
      "Epoch 46 completed in 0:08:26.604831\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 47/50\n",
      "Epoch: 47/50, Step: 14700, C Loss: 0.0342 ---- 17:56:36\n",
      "Epoch: 47/50, Step: 14800, C Loss: 0.0134 ---- 17:58:24\n",
      "Epoch: 47/50, Step: 14900, C Loss: 0.0660 ---- 18:00:13\n",
      "Epoch 47 completed in 0:05:45.289674\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 48/50\n",
      "Epoch: 48/50, Step: 15000, C Loss: 0.0461 ---- 18:02:02\n",
      "***** Eval Result (Source): 0.9991, Step: 15000\n",
      "***** Test Result (Target): 0.5195, Step: 15000\n",
      "Epoch: 48/50, Step: 15100, C Loss: 0.0316 ---- 18:06:30\n",
      "Epoch: 48/50, Step: 15200, C Loss: 0.0017 ---- 18:08:18\n",
      "Epoch: 48/50, Step: 15300, C Loss: 0.0941 ---- 18:10:06\n",
      "Epoch 48 completed in 0:08:24.931525\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 49/50\n",
      "Epoch: 49/50, Step: 15400, C Loss: 0.0066 ---- 18:11:55\n",
      "Epoch: 49/50, Step: 15500, C Loss: 0.3651 ---- 18:13:43\n",
      "***** Eval Result (Source): 0.9998, Step: 15500\n",
      "***** Test Result (Target): 0.5020, Step: 15500\n",
      "Epoch: 49/50, Step: 15600, C Loss: 0.0175 ---- 18:18:12\n",
      "Epoch 49 completed in 0:08:25.204233\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 50/50\n",
      "Epoch: 50/50, Step: 15700, C Loss: 0.0220 ---- 18:20:01\n",
      "Epoch: 50/50, Step: 15800, C Loss: 0.0064 ---- 18:21:49\n",
      "Epoch: 50/50, Step: 15900, C Loss: 0.0007 ---- 18:23:37\n",
      "Epoch 50 completed in 0:05:46.131667\n",
      "--------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "FINAL EVALUATION\n",
      "============================================================\n",
      "Final Source Accuracy: 0.9999\n",
      "Final Test Accuracy: 0.5283\n",
      "Training completed!\n",
      "Final test accuracy: 0.5283\n",
      "\n",
      "Training Statistics:\n",
      "Total steps: 15950\n",
      "Classification losses recorded: 160\n",
      "Target accuracies recorded: 32\n",
      "Best target accuracy during training: 0.5556\n",
      "Final target accuracy: 0.5020215633423181\n",
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(1, max_epoch + 1):\n",
    "    print(f\"\\nEpoch {epoch}/{max_epoch}\")\n",
    "    epoch_start_time = datetime.datetime.now()\n",
    "    \n",
    "    F.train()\n",
    "    C.train()\n",
    "    \n",
    "    for idx, (src_images, labels) in enumerate(source_loader):\n",
    "        src = src_images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        src_features = F(src)\n",
    "        class_outputs = C(src_features)\n",
    "        Lc = xe(class_outputs, labels)\n",
    "\n",
    "        F.zero_grad()\n",
    "        C.zero_grad()\n",
    "        \n",
    "        Lc.backward()\n",
    "        C_opt.step()\n",
    "        F_opt.step()\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            dt = datetime.datetime.now().strftime('%H:%M:%S')\n",
    "            print(f'Epoch: {epoch}/{max_epoch}, Step: {step}, C Loss: {Lc.item():.4f} ---- {dt}')\n",
    "            ll_c.append(Lc.item())\n",
    "\n",
    "        if step % 500 == 0:\n",
    "            F.eval()\n",
    "            C.eval()\n",
    "            with torch.no_grad():\n",
    "                correct_src = 0\n",
    "                total_src = 0\n",
    "                for eval_src, eval_labels in eval_loader:\n",
    "                    eval_src = eval_src.to(DEVICE)\n",
    "                    eval_labels = eval_labels.to(DEVICE)\n",
    "                    preds = C(F(eval_src))\n",
    "                    _, predicted = torch.max(preds, 1)\n",
    "                    correct_src += (predicted == eval_labels).sum().item()\n",
    "                    total_src += eval_labels.size(0)\n",
    "                acc_src = correct_src / total_src\n",
    "                print(f'***** Eval Result (Source): {acc_src:.4f}, Step: {step}')\n",
    "                correct_tgt = 0\n",
    "                total_tgt = 0\n",
    "                for test_tgt, test_labels in test_loader:\n",
    "                    test_tgt = test_tgt.to(DEVICE)\n",
    "                    test_labels = test_labels.to(DEVICE)\n",
    "                    preds = C(F(test_tgt))\n",
    "                    _, predicted = torch.max(preds, 1)\n",
    "                    correct_tgt += (predicted == test_labels).sum().item()\n",
    "                    total_tgt += test_labels.size(0)\n",
    "                acc_tgt = correct_tgt / total_tgt\n",
    "                print(f'***** Test Result (Target): {acc_tgt:.4f}, Step: {step}')\n",
    "                acc_lst.append(acc_tgt)\n",
    "            \n",
    "            F.train()\n",
    "            C.train()\n",
    "        \n",
    "        step += 1\n",
    "        \n",
    "        if step % 50 == 0:\n",
    "            clear_memory()\n",
    "    \n",
    "    epoch_time = datetime.datetime.now() - epoch_start_time\n",
    "    print(f\"Epoch {epoch} completed in {epoch_time}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    clear_memory()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "F.eval()\n",
    "C.eval()\n",
    "with torch.no_grad():\n",
    "    correct_src = 0\n",
    "    total_src = 0\n",
    "    for eval_src, eval_labels in eval_loader:\n",
    "        eval_src = eval_src.to(DEVICE)\n",
    "        eval_labels = eval_labels.to(DEVICE)\n",
    "        preds = C(F(eval_src))\n",
    "        _, predicted = torch.max(preds, 1)\n",
    "        correct_src += (predicted == eval_labels).sum().item()\n",
    "        total_src += eval_labels.size(0)\n",
    "    final_src_acc = correct_src / total_src\n",
    "    print(f'Final Source Accuracy: {final_src_acc:.4f}')\n",
    "    correct_tgt = 0\n",
    "    total_tgt = 0\n",
    "    for test_tgt, test_labels in test_loader:\n",
    "        test_tgt = test_tgt.to(DEVICE)\n",
    "        test_labels = test_labels.to(DEVICE)\n",
    "        preds = C(F(test_tgt))\n",
    "        _, predicted = torch.max(preds, 1)\n",
    "        correct_tgt += (predicted == test_labels).sum().item()\n",
    "        total_tgt += test_labels.size(0)\n",
    "    final_test_acc = correct_tgt / total_tgt\n",
    "    print(f'Final Test Accuracy: {final_test_acc:.4f}')\n",
    "\n",
    "print(\"Training completed!\")\n",
    "print(f\"Final test accuracy: {final_test_acc:.4f}\")\n",
    "\n",
    "print(f\"\\nTraining Statistics:\")\n",
    "print(f\"Total steps: {step}\")\n",
    "print(f\"Classification losses recorded: {len(ll_c)}\")\n",
    "print(f\"Target accuracies recorded: {len(acc_lst)}\")\n",
    "if acc_lst:\n",
    "    print(f\"Best target accuracy during training: {max(acc_lst):.4f}\")\n",
    "    print(f\"Final target accuracy: {acc_lst[-1] if acc_lst else 'N/A'}\")\n",
    "\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DANN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
